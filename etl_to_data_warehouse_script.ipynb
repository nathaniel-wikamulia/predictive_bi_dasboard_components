{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IrvSPqPPA5cl",
        "wCxS2GWYAtoR",
        "bEbN_nsMBF_c",
        "_h_F_GPBBKXd",
        "ims3UXeUBSPS",
        "OtJJq2s8uXAn",
        "e0V9FLy6x8M9",
        "MJDj0ZjK0xry",
        "uMaAeqQd2ESE",
        "jvpMxhN5K2he",
        "K3Po_P71RRY6",
        "XppvlM5vSDYk",
        "OW4SRCo9Smnz",
        "CR50VMCm855_",
        "n477yNTEDgXj",
        "KYPnuKWTEzwX",
        "2KuJchgSOmw1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Mount Google Drive"
      ],
      "metadata": {
        "id": "IrvSPqPPA5cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "#Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5wxbKbvCA2zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Library"
      ],
      "metadata": {
        "id": "wCxS2GWYAtoR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5laEAOfIAnK-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inisialisasi Lokasi CSV"
      ],
      "metadata": {
        "id": "bEbN_nsMBF_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_directory = \"drive/MyDrive/ETL Data Warehouse/\"\n",
        "\n",
        "directory_salh = base_directory + \"salh.csv\"\n",
        "directory_sald = base_directory + \"sald.csv\"\n",
        "directory_inv = base_directory + \"inv.csv\"\n",
        "directory_cust = base_directory + \"cust.csv\"\n",
        "directory_area = base_directory + \"area.csv\"\n",
        "directory_salesperson = base_directory + \"salperson.csv\"\n",
        "directory_rfm = base_directory + \"rfm_per_customer.csv\""
      ],
      "metadata": {
        "id": "S-velTI_BHPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ETL \"product_dim\""
      ],
      "metadata": {
        "id": "_h_F_GPBBKXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the dataset\n",
        "product_dim_df = pd.read_csv(directory_inv, \",\")\n",
        "etl_product_dim_df = product_dim_df"
      ],
      "metadata": {
        "id": "DUa-rDB0BcRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing unused columns\n",
        "etl_product_dim_df.drop(['SPRICE', 'UCOST', 'WEIGHT', 'UPDDATE', 'UPDTIME'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "PtegjZwxECrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the column names to match the star schema\n",
        "etl_product_dim_df.rename(columns = {\"ITEMNO\":\"product_id\", \"ITEMNAME\":\"product_name\"}, inplace=True)"
      ],
      "metadata": {
        "id": "mSs1E2l8BMVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the dataframe to CSV\n",
        "etl_product_dim_df.to_csv(\"product_dim.csv\", index=False)\n",
        "files.download(\"product_dim.csv\")"
      ],
      "metadata": {
        "id": "Z3S0R8ZlB6zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ETL \"customer_dim\""
      ],
      "metadata": {
        "id": "ims3UXeUBSPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the dataset\n",
        "customer_dim_df = pd.read_csv(directory_cust, \";\")\n",
        "etl_customer_dim_df = customer_dim_df"
      ],
      "metadata": {
        "id": "oNew3EJlCK3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing unused columns\n",
        "etl_customer_dim_df.drop(['CODE', 'AREACD', 'SALTYPE', 'ARBAL', 'ADDR1', 'ADDR2', 'ADDR3', 'PHONE', 'UPDDATE', 'UPDTIME'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "qcinkPa_EIRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the column names to match the star schema\n",
        "etl_customer_dim_df.rename(columns = {\"CUSTNAME\":\"customer_name\", \"INACTIVE\":\"customer_status\"}, inplace=True)"
      ],
      "metadata": {
        "id": "JWesAg_cBT4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the \"customer_status\" from False (boolean) to \"Active\" (string) and from True (boolean) to \"Inactive\" (string)\n",
        "etl_customer_dim_df.loc[etl_customer_dim_df[\"customer_status\"] == False, \"customer_status\"] = \"Aktif\"\n",
        "etl_customer_dim_df.loc[etl_customer_dim_df[\"customer_status\"] == True, \"customer_status\"] = \"Tidak Aktif\""
      ],
      "metadata": {
        "id": "hxJE2WReCfTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating surrogate key for the \"customer_dim\" table\n",
        "\n",
        "#Creating an empty dataframe with a column named \"customer_id\"\n",
        "surrogate_key_customer_dim_df = pd.DataFrame(columns = [\"customer_id\"])\n",
        "\n",
        "#Creating a surrogate key and then load the surrogate key into the empty dataframe that was previously created\n",
        "for i in range(1, len(etl_customer_dim_df)+1, 1):\n",
        "  surrogate_key_customer_dim_df = surrogate_key_customer_dim_df.append({'customer_id' : i}, ignore_index = True)\n",
        "\n",
        "#Merging the surrogate key into the \"customer_dim\" dataframe\n",
        "etl_customer_dim_df[\"customer_id\"] = surrogate_key_customer_dim_df"
      ],
      "metadata": {
        "id": "LY6Hy8Y-CaOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorting the columns to match the star schema\n",
        "etl_customer_dim_df = etl_customer_dim_df[[\"customer_id\",\"customer_name\",\"customer_status\"]]"
      ],
      "metadata": {
        "id": "Mtwy5O0oCXlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the dataframe to CSV\n",
        "etl_customer_dim_df.to_csv(\"customer_dim.csv\", index=False)\n",
        "files.download(\"customer_dim.csv\")"
      ],
      "metadata": {
        "id": "bHDT80ZsCU-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ETL \"date_dim\""
      ],
      "metadata": {
        "id": "OtJJq2s8uXAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the dataset\n",
        "date_dim_df = pd.read_csv(directory_salh)\n",
        "etl_date_dim_df = date_dim_df"
      ],
      "metadata": {
        "id": "XXxqxqf_ufj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing unused columns\n",
        "etl_date_dim_df.drop(['TRNO', 'CUSTCODE', 'STYPE', 'TOTAL', 'UPDDATE', 'UPDTIME'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "6W7bwTiTuqdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the column names to match the star schema\n",
        "etl_date_dim_df.rename(columns = {\"TRDATE\":\"transaction_date\"}, inplace=True)"
      ],
      "metadata": {
        "id": "oFh6H2LTusOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorting the dates in the table from the earliest date to the latest date\n",
        "etl_date_dim_df.sort_values(\"transaction_date\", inplace = True)"
      ],
      "metadata": {
        "id": "0S48xMTjuyDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping duplicate dates from the dataframe\n",
        "etl_date_dim_df.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "OjRss3hjv2su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resetting the dataframe index because the old dataframe index is not in order\n",
        "etl_date_dim_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "Bq6gqdjgwgOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating surrogate key for the \"date_dim\" table\n",
        "\n",
        "#Creating an empty dataframe with a column named \"date_id\"\n",
        "surrogate_key_date_dim_df = pd.DataFrame(columns = [\"date_id\"])\n",
        "\n",
        "#Creating a surrogate key and then load the surrogate key into the empty dataframe that was previously created\n",
        "for i in range(1, len(etl_date_dim_df)+1, 1):\n",
        "  surrogate_key_date_dim_df = surrogate_key_date_dim_df.append({'date_id' : i}, ignore_index = True)\n",
        "\n",
        "#Merging the surrogate key into the \"date_dim\" dataframe\n",
        "etl_date_dim_df[\"date_id\"] = surrogate_key_date_dim_df"
      ],
      "metadata": {
        "id": "rEWFUnvVwex8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorting the columns to match the star schema\n",
        "etl_date_dim_df = etl_date_dim_df[[\"date_id\",\"transaction_date\"]]"
      ],
      "metadata": {
        "id": "7NEsXlyswiVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating year, quarter, month, week, and day columns\n",
        "etl_date_dim_df[\"transaction_date\"] = pd.to_datetime(etl_date_dim_df[\"transaction_date\"])\n",
        "\n",
        "etl_date_dim_df['year'] = etl_date_dim_df['transaction_date'].dt.year\n",
        "etl_date_dim_df['quarter'] = etl_date_dim_df['transaction_date'].dt.quarter\n",
        "etl_date_dim_df['month'] = etl_date_dim_df['transaction_date'].dt.month\n",
        "etl_date_dim_df['week'] = etl_date_dim_df['transaction_date'].dt.week\n",
        "etl_date_dim_df['day'] = etl_date_dim_df['transaction_date'].dt.dayofyear"
      ],
      "metadata": {
        "id": "b7gO60EfuV3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the dataframe to CSV\n",
        "etl_date_dim_df.to_csv(\"date_dim.csv\", index=False)\n",
        "files.download(\"date_dim.csv\")"
      ],
      "metadata": {
        "id": "3KMIwP9mwnND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ETL \"area_dim\""
      ],
      "metadata": {
        "id": "e0V9FLy6x8M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the dataset\n",
        "area_dim_df = pd.read_csv(directory_area, \",\")\n",
        "etl_area_dim_df = area_dim_df"
      ],
      "metadata": {
        "id": "rVpgZ5TFyJM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing unused columns\n",
        "etl_area_dim_df.drop(['CODE', 'SALPERSON', 'UPDDATE', 'UPDTIME'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "KCTKqjV6yVZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the column names to match the star schema\n",
        "etl_area_dim_df.rename(columns = {\"DESC\":\"area_name\"}, inplace=True)"
      ],
      "metadata": {
        "id": "Ak45u0m-yVzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating surrogate key for the \"area_dim\" table\n",
        "\n",
        "#Creating an empty dataframe with a column named \"area_id\"\n",
        "surrogate_key_area_dim_df = pd.DataFrame(columns = [\"area_id\"])\n",
        "\n",
        "#Creating a surrogate key and then load the surrogate key into the empty dataframe that was previously created\n",
        "for i in range(1, len(etl_area_dim_df)+1, 1):\n",
        "  surrogate_key_area_dim_df = surrogate_key_area_dim_df.append({'area_id' : i}, ignore_index = True)\n",
        "\n",
        "#Merging the surrogate key into the \"area_dim\" dataframe \n",
        "etl_area_dim_df[\"area_id\"] = surrogate_key_area_dim_df"
      ],
      "metadata": {
        "id": "f7eHJIgKx91I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorting the columns to match the star schema\n",
        "etl_area_dim_df = etl_area_dim_df[[\"area_id\",\"area_name\"]]"
      ],
      "metadata": {
        "id": "TpiWFGD0yczN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding the \"latitude\" column\n",
        "latitude = [-6.598122, -6.715510, -6.705964, -6.396818, -6.569738, -7.443695, -6.937865, -6.606161]\n",
        "etl_area_dim_df[\"latitude\"] = latitude"
      ],
      "metadata": {
        "id": "Np16V9bhydwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding the \"longitude\" column\n",
        "longitude = [106.802569, 107.014857, 107.753022, 106.81105, 106.628599, 107.094473, 106.926579, 106.802256]\n",
        "etl_area_dim_df[\"longitude\"] = longitude"
      ],
      "metadata": {
        "id": "EPz6NgYqyeuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the dataframe to CSV\n",
        "etl_area_dim_df.to_csv(\"area_dim.csv\", index=False)\n",
        "files.download(\"area_dim.csv\")"
      ],
      "metadata": {
        "id": "n4VHt78dygef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ETL \"sales_person_dim\""
      ],
      "metadata": {
        "id": "MJDj0ZjK0xry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the dataset\n",
        "sales_person_dim_df = pd.read_csv(directory_salesperson, \",\")\n",
        "etl_sales_person_dim_df = sales_person_dim_df"
      ],
      "metadata": {
        "id": "gS0HQajz0-oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing unused columns\n",
        "etl_sales_person_dim_df.drop(['DOB', 'GENDER', 'SALARY', 'UPDDATE', 'UPDTIME'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "y28R7tbk1Ihb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the column names to match the star schema\n",
        "etl_sales_person_dim_df.rename(columns = {\"SALPCODE\":\"sales_person_id\", \"SALPNAME\":\"sales_person_name\"}, inplace=True)"
      ],
      "metadata": {
        "id": "pd0_Om1H1L2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the dataframe to CSV\n",
        "etl_sales_person_dim_df.to_csv(\"sales_person_dim.csv\", index=False)\n",
        "files.download(\"sales_person_dim.csv\")"
      ],
      "metadata": {
        "id": "dBFfvk5k0ws9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ETL \"sales_type_dim\""
      ],
      "metadata": {
        "id": "uMaAeqQd2ESE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the dataset\n",
        "sales_type_dim_df = pd.read_csv(directory_salh)\n",
        "etl_sales_type_dim_df = sales_type_dim_df"
      ],
      "metadata": {
        "id": "_GgzILMM2Q2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing unused columns\n",
        "etl_sales_type_dim_df.drop(['TRNO', 'CUSTCODE','TRDATE', 'TOTAL', 'UPDDATE', 'UPDTIME'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ZC9HjRpC2SHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the column names to match the star schema\n",
        "etl_sales_type_dim_df.rename(columns = {\"STYPE\":\"sales_type_name\"}, inplace=True)"
      ],
      "metadata": {
        "id": "kZ7eLv2v2T2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping duplicate items from the dataframe\n",
        "etl_sales_type_dim_df.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "eK6wHUkT2d1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resetting the dataframe index because the old dataframe index is not in order\n",
        "etl_sales_type_dim_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "aRyD3Yp92ff5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating surrogate key for the \"sales_type_dim\" table\n",
        "\n",
        "#Creating an empty dataframe with a column named \"sales_type_id\"\n",
        "surrogate_key_sales_type_dim_df = pd.DataFrame(columns = [\"sales_type_id\"])\n",
        "\n",
        "#Creating a surrogate key and then load the surrogate key into the empty dataframe that was previously created\n",
        "for i in range(1, len(etl_sales_type_dim_df)+1, 1):\n",
        "  surrogate_key_sales_type_dim_df = surrogate_key_sales_type_dim_df.append({'sales_type_id' : i}, ignore_index = True)\n",
        "\n",
        "#Merging the surrogate key into the \"sales_type_dim\" dataframe \n",
        "etl_sales_type_dim_df[\"sales_type_id\"] = surrogate_key_sales_type_dim_df"
      ],
      "metadata": {
        "id": "MzwneQO62CfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorting the columns to match the star schema\n",
        "etl_sales_type_dim_df = etl_sales_type_dim_df[[\"sales_type_id\",\"sales_type_name\"]]"
      ],
      "metadata": {
        "id": "A7TXXvky2lM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the \"sales_type_name\" from \"T\" to \"Tunai\" and from \"K\" to \"Kredit\"\n",
        "etl_sales_type_dim_df.loc[etl_sales_type_dim_df[\"sales_type_name\"] == \"T\", \"sales_type_name\"] = \"Tunai\"\n",
        "etl_sales_type_dim_df.loc[etl_sales_type_dim_df[\"sales_type_name\"] == \"K\", \"sales_type_name\"] = \"Kredit\""
      ],
      "metadata": {
        "id": "QOSnHSr_2me4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the dataframe to CSV\n",
        "etl_sales_type_dim_df.to_csv(\"sales_type_dim.csv\", index=False)\n",
        "files.download(\"sales_type_dim.csv\")"
      ],
      "metadata": {
        "id": "q3j63Han2nV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ETL \"sales_approval_dim\""
      ],
      "metadata": {
        "id": "jvpMxhN5K2he"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the dataset\n",
        "sales_approval_dim_df = pd.read_csv(directory_sald)\n",
        "etl_sales_approval_dim_df = sales_approval_dim_df"
      ],
      "metadata": {
        "id": "ahVPSRn1K7m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing unused columns\n",
        "etl_sales_approval_dim_df.drop(['SALDCODE', 'TRNO','ITEMNO', 'LINENO', 'UPRICE', 'UCOST', 'QTY', 'QTYRET', 'PREDICTQTY', 'PREDICTRET', 'DISCAMT', 'AMOUNT', 'UPDDATE', 'UPDTIME'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "NBD1150tK_NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the column names to match the star schema\n",
        "etl_sales_approval_dim_df.rename(columns = {\"APPROVED\":\"sales_approval_status\"}, inplace=True)"
      ],
      "metadata": {
        "id": "oMlFy3TiLIaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping duplicate items from the dataframe\n",
        "etl_sales_approval_dim_df.drop_duplicates(inplace = True)"
      ],
      "metadata": {
        "id": "gR5FlxmoLL9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resetting the dataframe index because the old dataframe index is not in order\n",
        "etl_sales_approval_dim_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "_qv_CtOdLOuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding a new \"sales_approval_status\" called \"False\" into the \"sales_approval_dim\" dataframe\n",
        "approval_false = pd.DataFrame({\"sales_approval_status\":[\"False\"]})\n",
        "etl_sales_approval_dim_df = etl_sales_approval_dim_df.append(approval_false, ignore_index = True)"
      ],
      "metadata": {
        "id": "zkuVYwDQLoyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating surrogate key for the \"sales_approval_dim\" table\n",
        "\n",
        "#Creating an empty dataframe with a column named \"sales_approval_id\"\n",
        "surrogate_key_sales_approval_dim_df = pd.DataFrame(columns = [\"sales_approval_id\"])\n",
        "\n",
        "#Creating a surrogate key and then load the surrogate key into the empty dataframe that was previously created\n",
        "for i in range(1, len(etl_sales_approval_dim_df)+1, 1):\n",
        "  surrogate_key_sales_approval_dim_df = surrogate_key_sales_approval_dim_df.append({'sales_approval_id' : i}, ignore_index = True)\n",
        "\n",
        "#Merging the surrogate key into the \"sales_approval_dim\" dataframe  \n",
        "etl_sales_approval_dim_df[\"sales_approval_id\"] = surrogate_key_sales_approval_dim_df"
      ],
      "metadata": {
        "id": "MSdzNDvOL6Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorting the columns to match the star schema\n",
        "etl_sales_approval_dim_df = etl_sales_approval_dim_df[[\"sales_approval_id\",\"sales_approval_status\"]]"
      ],
      "metadata": {
        "id": "Sw6DHTb2L9Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the \"sales_approval_status\" from \"True\" to \"Disetujui\" and from \"False\" to \"Tidak Disetujui\"\n",
        "etl_sales_approval_dim_df.loc[etl_sales_approval_dim_df[\"sales_approval_status\"] == True, \"sales_approval_status\"] = \"Disetujui\"\n",
        "etl_sales_approval_dim_df.loc[etl_sales_approval_dim_df[\"sales_approval_status\"] == \"False\", \"sales_approval_status\"] = \"Tidak Disetujui\""
      ],
      "metadata": {
        "id": "hhAqxrj0K4vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the dataframe to CSV\n",
        "etl_sales_approval_dim_df.to_csv(\"sales_approval_dim.csv\", index=False)\n",
        "files.download(\"sales_approval_dim.csv\")"
      ],
      "metadata": {
        "id": "pHqtW4o1L__n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ETL \"rfm_segmentation_dim\""
      ],
      "metadata": {
        "id": "K3Po_P71RRY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the \"rfm_segmentation_dim\" table and data \n",
        "data = [[0, \"Low Spender\"], [1, \"Lost Customer\"], [2, \"Ex Best Customer\"],[3, \"Best Customer\"], [4, \"Need Reactivation\"], [5, \"Ex Low Spender\"]]\n",
        "\n",
        "rfm_segmentation_df = pd.DataFrame(data, columns=['rfm_segmentation_id', 'customer_group_name'])"
      ],
      "metadata": {
        "id": "QLdn-E1GRS3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the dataframe to CSV\n",
        "rfm_segmentation_df.to_csv(\"rfm_segmentation_dim.csv\", index=False)\n",
        "files.download(\"rfm_segmentation_dim.csv\")"
      ],
      "metadata": {
        "id": "oUutOtiMRhbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ETL \"sales_detail_fact\""
      ],
      "metadata": {
        "id": "XppvlM5vSDYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perform JOIN to All Transactional Database Tables"
      ],
      "metadata": {
        "id": "OW4SRCo9Smnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading the dataset\n",
        "cust_table_df = pd.read_csv(directory_cust, \";\")\n",
        "salh_table_df = pd.read_csv(directory_salh)\n",
        "sald_table_df = pd.read_csv(directory_sald)\n",
        "product_dim_df = pd.read_csv(directory_inv)\n",
        "area_dim_df = pd.read_csv(directory_area)\n",
        "sales_person_dim_df = pd.read_csv(directory_salesperson)"
      ],
      "metadata": {
        "id": "RegRHt3mSbON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the \"SALD\" table with the \"SALH\" table\n",
        "cust_table_df.rename(columns={\"CODE\": \"CUSTCODE\"}, inplace=True)\n",
        "\n",
        "sald_join_salh_df = sald_table_df.merge(salh_table_df,\n",
        "                    on=['TRNO'],\n",
        "                    how=\"inner\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "5tJ-FOKVS7DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the \"SALD, SALH\" table with the \"CUST\" table\n",
        "sald_join_salh_join_cust_df = sald_join_salh_df.merge(cust_table_df,\n",
        "                    on=['CUSTCODE'],\n",
        "                    how=\"inner\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "ZkxrPeqES_Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the \"SALD, SALH, CUST\" table with the \"INV\" table\n",
        "inv_to_cust_df = sald_join_salh_join_cust_df.merge(product_dim_df,\n",
        "                    on=['ITEMNO'],\n",
        "                    how=\"inner\"\n",
        "                    )\n",
        "\n",
        "#Removing unused columns\n",
        "inv_to_cust_df.drop(['UPDDATE_x', 'UPDTIME_x','UPDDATE_y', 'UPDTIME_y','UCOST_y','WEIGHT','PHONE','ADDR1','ADDR2','ADDR3', 'SPRICE'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "bUdr9Dg4TAOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the \"SALD, SALH, CUST, INV\" table with the \"AREA\" table\n",
        "area_dim_df.rename(columns={\"CODE\": \"AREACD\"}, inplace=True)\n",
        "\n",
        "inv_to_area_df = inv_to_cust_df.merge(area_dim_df,\n",
        "                    on=['AREACD'],\n",
        "                    how=\"inner\"\n",
        "                    )\n",
        "\n",
        "#Removing unused columns\n",
        "inv_to_area_df.drop(['UPDDATE', 'UPDTIME'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Yehvo7TtTDSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the \"SALD, SALH, CUST, INV, AREA\" table with the \"SALPERSON\" table\n",
        "inv_to_area_df.rename(columns={\"SALPERSON\": \"SALPCODE\"}, inplace=True)\n",
        "\n",
        "inv_to_salp_df = inv_to_area_df.merge(sales_person_dim_df,\n",
        "                    on=['SALPCODE'],\n",
        "                    how=\"inner\"\n",
        "                    )\n",
        "\n",
        "#Removing unused columns\n",
        "inv_to_salp_df.drop(['UPDDATE', 'UPDTIME'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "KvriAVWeTOA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perform JOIN to All Data Warehouse Tables"
      ],
      "metadata": {
        "id": "CR50VMCm855_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the transactional database dataframe with the \"product_dim\" dataframe to get the \"product_id\"\n",
        "inv_to_salp_df.rename(columns={\"ITEMNAME\": \"product_name\"}, inplace=True)\n",
        "\n",
        "df_after_join_product_dim = inv_to_salp_df.merge(etl_product_dim_df,\n",
        "                    on=['product_name'],\n",
        "                    how=\"inner\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "SRJezf_J9L_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the transactional database dataframe with the \"customer_dim\" dataframe to get the \"customer_id\"\n",
        "df_after_join_product_dim.rename(columns={\"CUSTNAME\": \"customer_name\"}, inplace=True)\n",
        "\n",
        "df_after_join_customer_dim = df_after_join_product_dim.merge(etl_customer_dim_df,\n",
        "                    on=['customer_name'],\n",
        "                    how=\"inner\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "kKu-v34_9OT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the transactional database dataframe with the \"date_dim\" dataframe to get \"date_id\"\n",
        "df_after_join_customer_dim.rename(columns={\"TRDATE\": \"transaction_date\"}, inplace=True)\n",
        "\n",
        "df_after_join_customer_dim['transaction_date'] = pd.to_datetime(df_after_join_customer_dim['transaction_date'])\n",
        "\n",
        "df_after_join_date_dim = df_after_join_customer_dim.merge(etl_date_dim_df,\n",
        "                    on=['transaction_date'],\n",
        "                    how=\"inner\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "f7YTqBT49Qyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the transactional database dataframe with the \"sales_person_dim\" dataframe to get the \"sales_person_id\"\n",
        "df_after_join_date_dim.rename(columns={\"SALPNAME\": \"sales_person_name\"}, inplace=True)\n",
        "\n",
        "df_after_join_sales_person_dim = df_after_join_date_dim.merge(etl_sales_person_dim_df,\n",
        "                    on=['sales_person_name'],\n",
        "                    how=\"inner\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "uXNYx3Vw9R-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the transactional database dataframe with the \"area_dim\" dataframe to get the \"area_id\"\n",
        "df_after_join_sales_person_dim.rename(columns={\"DESC\": \"area_name\"}, inplace=True)\n",
        "\n",
        "df_after_join_area_dim = df_after_join_sales_person_dim.merge(etl_area_dim_df,\n",
        "                    on=['area_name'],\n",
        "                    how=\"inner\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "CE1T_S0H9TA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the transactional database dataframe with the \"sales_type_dim\" dataframe to get \"sales_type_id\"\n",
        "df_after_join_area_dim.loc[df_after_join_area_dim[\"STYPE\"] == \"T\", \"STYPE\"] = \"Tunai\"\n",
        "df_after_join_area_dim.loc[df_after_join_area_dim[\"STYPE\"] == \"K\", \"STYPE\"] = \"Kredit\"\n",
        "\n",
        "df_after_join_area_dim.rename(columns={\"STYPE\": \"sales_type_name\"}, inplace=True)\n",
        "\n",
        "df_after_join_sales_type_dim = df_after_join_area_dim.merge(etl_sales_type_dim_df,\n",
        "                    on=['sales_type_name'],\n",
        "                    how=\"inner\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "OEOqfbn39UUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the transactional database dataframe with the \"sales_approval_dim\" dataframe to get the \"sales_approval_id\"\n",
        "df_after_join_sales_type_dim.loc[df_after_join_sales_type_dim[\"APPROVED\"] == True, \"APPROVED\"] = \"Disetujui\"\n",
        "df_after_join_sales_type_dim.loc[df_after_join_sales_type_dim[\"APPROVED\"] == False, \"APPROVED\"] = \"Tidak Disetujui\"\n",
        "\n",
        "df_after_join_sales_type_dim.rename(columns={\"APPROVED\": \"sales_approval_status\"}, inplace=True)\n",
        "\n",
        "df_after_join_sales_approval_dim = df_after_join_sales_type_dim.merge(etl_sales_approval_dim_df,\n",
        "                    on=['sales_approval_status'],\n",
        "                    how=\"inner\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "71c1w1349VqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#JOIN the transactional database dataframe with the \"rfm_segmentation_dim\" dataframe to get the recency, frequency, and monetary value\n",
        "\n",
        "#JOIN the clustering result with the RFM category dataframe\n",
        "rfm_per_customer_df = pd.read_csv(directory_rfm, \",\")\n",
        "\n",
        "rfm_per_customer_df.drop(['R', 'F','M'], axis=1, inplace=True)\n",
        "\n",
        "rfm_per_customer_df.rename(columns={\"Cluster\": \"rfm_segmentation_id\"}, inplace=True)\n",
        "\n",
        "df_rfm_joined = rfm_per_customer_df.merge(rfm_segmentation_df,\n",
        "                    on=['rfm_segmentation_id'],\n",
        "                    how=\"inner\"\n",
        "                    )\n",
        "\n",
        "df_rfm_joined.rename(columns={\"customer_id\": \"customer_name\"}, inplace=True)\n",
        "\n",
        "#JOIN the RFM table with the \"sales_detail_fact\" dataframe\n",
        "df_after_join_rfm_dim = df_after_join_sales_approval_dim.merge(df_rfm_joined,\n",
        "                    on=['customer_name'],\n",
        "                    how=\"inner\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "ihrI38Ko9XBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reorganizing The \"sales_detail_fact\" Dataframe To Match The Star Schema"
      ],
      "metadata": {
        "id": "n477yNTEDgXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "etl_sales_detail_fact = df_after_join_rfm_dim\n",
        "\n",
        "#Removing unused columns\n",
        "etl_sales_detail_fact.drop(['product_name', 'INACTIVE', 'area_name','sales_person_name', 'DOB','GENDER','SALARY','SALTYPE', 'LINENO','sales_approval_status','customer_status','customer_group_name','year','quarter','month','week', 'day','latitude','longitude', 'transaction_date', 'sales_type_name','AREACD', 'CUSTCODE', 'customer_name'], axis=1, inplace=True)\n",
        "\n",
        "#Changing the column names to match the star schema\n",
        "etl_sales_detail_fact.rename(columns={\"SALDCODE\": \"old_sales_detail_id\", \"TRNO\": \"old_sales_header_id\", \"ITEMNO\":\"product_id\", \"UPRICE\": \"price\", \"UCOST_x\": \"production_cost\", \"QTY\":\"quantity\", \"QTYRET\":\"return_quantity\", \"PREDICTQTY\":\"predicted_buy_quantity\", \"PREDICTRET\": \"predicted_return_quantity\", \"DISCAMT\": \"discount_amount\", \"AMOUNT\":\"sub_total\", \"TOTAL\":\"grand_total\", \"ARBAL\":\"accounts_receivable\", \"SALPCODE\": \"sales_person_id\"}, inplace=True)\n",
        "\n",
        "fact_table_copy = etl_sales_detail_fact\n",
        "\n",
        "#Removing duplicate columns\n",
        "no_duplicate_fact  = fact_table_copy.loc[:,~fact_table_copy.columns.duplicated()]\n",
        "\n",
        "#Adding the \"actual_demand\" and \"predicted_demand\" columns\n",
        "no_duplicate_fact['actual_demand'] = no_duplicate_fact['quantity'] - no_duplicate_fact['return_quantity']\n",
        "no_duplicate_fact['predicted_demand'] = no_duplicate_fact['predicted_buy_quantity'] - no_duplicate_fact['predicted_return_quantity']\n",
        "\n",
        "#Sorting the columns to match the star schema\n",
        "no_duplicate_fact_reordered = no_duplicate_fact[['old_sales_header_id', 'old_sales_detail_id', 'product_id', 'customer_id', 'date_id', 'sales_person_id', 'area_id', 'sales_type_id', 'sales_approval_id', 'rfm_segmentation_id', 'price', 'production_cost', 'accounts_receivable', 'predicted_buy_quantity', 'predicted_return_quantity', 'predicted_demand', 'quantity',  'return_quantity', 'actual_demand', 'discount_amount', 'sub_total', 'grand_total', 'recency', 'frequency', 'monetary_value']]"
      ],
      "metadata": {
        "id": "VAp3LbkFD9ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating Composite Key For The \"sales_detail_fact\" Table"
      ],
      "metadata": {
        "id": "KYPnuKWTEzwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "composite_key_sales_detail_fact_df = no_duplicate_fact_reordered['old_sales_header_id'] + '-' +  no_duplicate_fact_reordered['old_sales_detail_id'] + '-' + no_duplicate_fact_reordered['product_id'].map(str) + '-' +  no_duplicate_fact_reordered['customer_id'].map(str) + '-' + no_duplicate_fact_reordered['date_id'].map(str) + '-' +  no_duplicate_fact_reordered['sales_person_id'].map(str) + '-' + no_duplicate_fact_reordered['area_id'].map(str) + '-' +  no_duplicate_fact_reordered['sales_type_id'].map(str)  + '-' +  no_duplicate_fact_reordered['sales_approval_id'].map(str) + '-' + no_duplicate_fact_reordered['rfm_segmentation_id'].map(str)\n",
        "\n",
        "#Combining \"sales_detail_fact\" dataframe with the composite key dataframe\n",
        "no_duplicate_fact_reordered = no_duplicate_fact_reordered.merge(composite_key_sales_detail_fact_df.rename('sales_detail_fact_id'), left_index=True, right_index=True)\n",
        "\n",
        "#Sorting the columns to match the star schema\n",
        "no_duplicate_fact_reordered = no_duplicate_fact_reordered[[\"sales_detail_fact_id\",'old_sales_header_id', 'old_sales_detail_id', 'product_id', 'customer_id', 'date_id', 'sales_person_id', 'area_id', 'sales_type_id', 'sales_approval_id', 'rfm_segmentation_id', 'price', 'production_cost', 'accounts_receivable', 'predicted_buy_quantity', 'predicted_return_quantity', 'predicted_demand', 'quantity',  'return_quantity', 'actual_demand', 'discount_amount', 'sub_total', 'grand_total', 'recency', 'frequency', 'monetary_value']]"
      ],
      "metadata": {
        "id": "kBTUVfafEyY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting The \"sales_detail_fact\" Dataframe to CSV"
      ],
      "metadata": {
        "id": "2KuJchgSOmw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_duplicate_fact_reordered.to_csv(\"sales_detail_fact.csv\", index=False)\n",
        "files.download(\"sales_detail_fact.csv\")"
      ],
      "metadata": {
        "id": "0_H3-lpIOg00"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}